|          Course Name          |   Topic    |   Professor   |      Date       | Tags |
| :---------------------------: | :--------: | :-----------: | :-------------: | :--: |
| **Data Laws and Regulations** | The AI Act | Marina Teller | 27 f√©vrier 2025 |      |
# Summary
*The AI Act is a risk-based framework which has a stated goal of developing a human-centric AI, but is built off the provisions for creating a well-functioning market. The main focus of the Act is the high-risk category which outlines many requirements that actors must follow. This compliance-based framework also has stiff penalties for companies who do not comply.*

# Key Takeaways
1. The AI Act is a horizontal normative approach based on the risk generated by the specific technology coupled with voluntary codes of conduct for the systems which pose the lowest risk
2. The AI Act is an extraterritorial piece of legislation
3. AI systems on free or open-source licenses (excluding high-risk) are excluded from the AI Act
4. The legal basis of the AI Act is article 114 on the <mark style="background: #FFB86CA6;">well-functioning of the European market</mark>
5. A model represents a systemic risk if the cumulative compute used for its training is $\gt 10^{25}$ floating point operations 

# Definitions
- Brussels Effect: When you set the rules for a market, you get to design the market
- Extraterritorial legislation: Legislation which has applications and impacts on activities happening beyond the physical jurisdiction in which the law exists
	- PATRIOT act
- [[Ethics and Laws Overview|Artificial Intelligence]]: AI is defined by the AI Act as a machine-based system that is designed to operator with varying levels of autonomy and that may exhibit adaptiveness after deployment, and that, for explicit of implicit objectives, <mark style="background: #FFB86CA6;">infers</mark>, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments
	- Includes ML approaches, logic and knowledge-based approaches, and statistical approaches
- Risk: The combination of the probability of an occurrence of harm and the severity of that harm
- General-Purpose AI: An AI model which is capable to competently perform a wide range of distinct tasks and displays significant generality

# Additional Resources
- [AI Act - Raw Text](https://eur-lex.europa.eu/resource.html?uri=cellar:e0649735-a372-11eb-9585-01aa75ed71a1.0001.02/DOC_1&format=PDF)
- [High-Risk Use Cases - Article III](https://artificialintelligenceact.eu/annex/3/)

# Notes
## Introduction to and Goals of the AI Act
- Act was ratified in 2024 and immediately took effect
- Goal is to align AI systems with a human-centric vision
- Part of a larger package of rules including
	- Communication promoting a European approach to AI
	- New coordination plan (revision of the 2018 plan)
	- Proposal for a regulation reforming the machinery directive
- This path is a median among those who want strong and those who want weak regulation
- Legal basis is the well-functioning of the European market (Article 114)
	- Explains why we are not concerned with non-professional activities
	- Trying to ensure Europe stays competitive in AI
## Who is Affected by the AI Act?
- Actors under the AI Act
	- Providers (creators): Any entity that develops or has developed for them an AI system and places it on the market into service under their own name or trademark <mark style="background: #FFB86CA6;">whether for payment or free of charge</mark>
	- Deployers (users): An entity using an AI system except for personal, non-professional activities
	- Authorized representatives (for non-EU providers): An entity located or established in the EU who has received and accepted a written mandate from a provider to perform and carry out on its behalf obligations and procedures established by the AI act
	- Importers: An entity in the EU that places an AI system 
	- Operators: Provider, product manufacturer, deployer, authorized rep, importer, or distributor
	- Distributors: An entity other than the provider or importer who makes an AI system available on the market within the EU
	- Affected Person
- Scope
	- Providers placing onto the market or putting into service AI models in the EU
	- Deployers of AI systems located or established in the EU
	- Providers and deployers that are located or established in a third country where the output used by the AI system is used in the EU
	- Importers and distributors of AI systems
	- Product manufacturers placing onto the market or putting into service AI systems together with their product and under their own name or [[Intellectual Property|trademark]]
	- Authorized representatives of providers
	- Affected persons located in the EU
	- Exclusions
		- <mark style="background: #FFB86CA6;">AI systems developed or used for military purposes are excluded</mark>
		- Non-professional uses and scientific R&D is also excluded as long as the sole purpose is R&D
## Risk-Based Framework
- Designed a pyramid of risk
	- ![[Pasted image 20250309174646.png]]
- Also created an assessment list for trustworthy artificial intelligence
- Unacceptable risk (Chap II, Art. 5)
	- Completely prohibited
	- Includes social scoring systems and manipulative AI
	- Largely societal-level use cases (excluding military)
- High risk
	- Used as a safety component or a product covered by EU laws in [Annex 1](https://artificialintelligenceact.eu/annex/1/)
	- Annex III Use Cases
		- Biometrics
		- Critical infrastructure 
		- Education
		- Employment
		- Access to and enjoyment of essential private or public services and benefits
		- Law enforecement
		- Migration, asylum, border control management,
		- Justice and democratic processes
	- Requirements for use
		- Risk management system throughout the whole lifecycle
		- Data governance to ensure datasets are relevant, sufficiently, representative, and (best extent possible) free of errors
		- Create technical documentation
		- Design the system for record keeping to identify national level risks and substantial modifications
		- Instructions for use to downstream deployers
		- Design to allow deployers to implement human oversight
		- Achieve appropriate levels of accuracy, robustness, and cybersecurity
		- Establish a quality management system
- Low risk
	- Chatbots, emotion recognition, deep fakes
	- Obligation of transparency towards users
		- We have to let the users know they are interacting with an AI system
- Minimal risk
	- No explicit definition but the uses are thus not regulated by the AI Act
## Enforcement and Penalties
- Act is based on compliance. The actor must put in place the elements necessary to comply
	- Companies are expected to comply at the start of the process
- Standards organizations help to create the processes and procedures which organizations can use to ensure they are in compliance
- Enforcement bodies
	- AI Office (EU Commission)
	- AI Board
	- Scientific Panel
	- Advisory Forum
- Penalties
	- Using prohibited AI practices
		- Up to 40 million euros or 7% of worldwide annual turnover - whichever is higher
	- Non-compliance with data governance requirements and/or provision of information
		- Up to 20 million euros or 4% of worldwide turnover - whichever is higher
	- Non-compliance with any other requirements or regulations
		- Up to 10 million euros or 2% of worldwide turnover - whichever is higher
## General-Purpose AI
- Special additional requirements
	- Technical documentation including training and testing process and evaluation results
	- Information and documentation about capabilities and limitation to supply to downstream providers
	- Establish a policy to respect the [[Intellectual Property|Copyright Directive]]
	- Publish a sufficiently detailed summary about the content used for training
- It is these models which can present system risks
- For models with systemic risk, there are additional requirements
	- Model evaluations including conducting and documenting adversarial testing
	- Assess and mitigate possible systemic risks
	- Track, document and report serious incident and corrective measures to the AI Office
	- Ensure adequate level of cybersecurity protection
- Compliance is shown if they adhere to a code of practice until European harmonized standards are published
	- Compliance with standards will be a presumption of conformity